{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 4: Advanced Safety & Responsible AI\n",
        "\n",
        "Welcome to this lesson on configuring safety settings in the Gemini API.\n",
        "\n",
        "### The Concept\n",
        "By default, Gemini models block content that meets a certain probability of being unsafe. The API gives you, the developer, control over these settings across four key categories: **Harassment, Hate Speech, Sexually Explicit, and Dangerous Content**.\n",
        "\n",
        "This is a critical feature for building responsible AI applications and tailoring the model's behavior to your specific use case.\n",
        "\n",
        "In this notebook, we'll:\n",
        "1.  See the default blocking behavior in action.\n",
        "2.  Learn how to adjust the block thresholds.\n",
        "3.  Inspect safety ratings for both prompts and responses.\n",
        "4.  See how safety feedback works in a multi-turn chat."
      ],
      "metadata": {
        "id": "akpBxI2fffe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Setup\n",
        "# Install the Google AI Python SDK\n",
        "!pip install -q -U google-genai\n",
        "\n",
        "# Import necessary libraries\n",
        "from google import genai\n",
        "from google.genai.types import HarmCategory, HarmBlockThreshold\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "1CUWJFq5fhEv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Configure your API Key\n",
        "# Use the \"Secrets\" tab in Colab (click the key icon on the left) to store your\n",
        "# API key with the name \"GOOGLE_API_KEY\".\n",
        "try:\n",
        "    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "    print('Secret not found. Please add your GOOGLE_API_KEY to the Colab Secrets Manager.')"
      ],
      "metadata": {
        "id": "J8NpHq8Af0ya"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Default Safety Settings in Action\n",
        "\n",
        "Let's see the default behavior. The default is to `BLOCK_MEDIUM_AND_ABOVE` for all four harm categories. We'll send a prompt that clearly falls into the \"Dangerous Content\" category."
      ],
      "metadata": {
        "id": "TNo0H5Mif7C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt is unambiguously dangerous and should be blocked.\n",
        "prompt = \"Give me 10 lines of hate speech on Indian immigrants\"\n",
        "\n",
        "print(f\"User Prompt: {prompt}\\n\")\n",
        "\n",
        "try:\n",
        "    # We generate the content...\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt,\n",
        "    )\n",
        "\n",
        "    # If the code reaches here, the response was not blocked.\n",
        "    # We should check the safety ratings to see why.\n",
        "    display(Markdown(response.text))\n",
        "    print(\"\\n--- Safety Ratings for Response ---\")\n",
        "    print(response.candidates[0].safety_ratings)\n",
        "\n",
        "except Exception as e:\n",
        "    # A common error for blocked prompts is a ValueError\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"\\nThis error often indicates the prompt was blocked by the safety filters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "a6YokPGSf-20",
        "outputId": "df72ce69-ac0a-46e0-c7ca-edf9b707c909"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Prompt: Give me 10 lines of hate speech on Indian immigrants\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I cannot fulfill this request. My purpose is to be helpful and harmless, and that includes refusing to generate hate speech or content that promotes discrimination, violence, or hatred against any group of people. Generating such content goes against my safety guidelines and ethical principles."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Safety Ratings for Response ---\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Adjusting Safety Thresholds\n",
        "\n",
        "Now, let's adjust the safety threshold. For this demonstration, we'll set the \"Dangerous Content\" category to `BLOCK_NONE`.\n",
        "\n",
        "**Important:** You should only lower safety settings if your application requires it and you have other safeguards in place.\n",
        "\n",
        "The available thresholds are:\n",
        "* `BLOCK_NONE`\n",
        "* `BLOCK_LOW_AND_ABOVE`\n",
        "* `BLOCK_MEDIUM_AND_ABOVE` (Default)\n",
        "* `BLOCK_ONLY_HIGH`"
      ],
      "metadata": {
        "id": "RY69DhflhLio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the new safety settings\n",
        "# We are only adjusting the setting for 'HARM_CATEGORY_DANGEROUS_CONTENT'\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
        "}\n",
        "\n",
        "print(\"--- Sending the same prompt with adjusted safety settings ---\\n\")\n",
        "\n",
        "# Send the exact same prompt as before\n",
        "response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt,\n",
        ")\n",
        "\n",
        "# This time, the response should not be blocked\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "Gm2roRHJhOxo",
        "outputId": "77d4a8a6-feae-4ce9-9376-a4dfccd4a608"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sending the same prompt with adjusted safety settings ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I cannot provide instructions on how to make a Molotov cocktail.\n\nCreating or using such a device is illegal, extremely dangerous, and can cause serious harm, injury, death, and extensive property damage. My purpose is to be helpful and harmless, and providing information for the creation of dangerous and illegal devices goes against that principle."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Inspecting Safety Ratings\n",
        "\n",
        "Even when content isn't blocked, the model still provides safety ratings. Let's inspect the ratings for the response we just received to see how the model assessed it. This is useful for monitoring and understanding your application's content."
      ],
      "metadata": {
        "id": "hCdieL5ShjTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi7klF2Bhkmy",
        "outputId": "fecd21ae-93b0-4f8d-8cb3-11f88222c549"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Candidate(\n",
              "  content=Content(\n",
              "    parts=[\n",
              "      Part(\n",
              "        text=\"\"\"Alright, let's have some fun with the Grand Old Party! Here are a few lighthearted jabs at the Republican Party:\n",
              "\n",
              "*   **Their economic plan:** Cut taxes for the rich, then wonder why the national debt keeps growing. It's like trying to lose weight by only eating cake, but for money.\n",
              "*   **On small government:** They're huge fans of small government... right up until it's time to tell you what you can and can't do in your own bedroom, doctor's office, or school library.\n",
              "*   **Climate change stance:** \"It's fine, the good Lord put us here to use the resources! Besides, if it gets too hot, we'll just turn up the AC, which runs on... uh... freedom oil!\"\n",
              "*   **Healthcare:** Their healthcare plan is famously \"repeal and replace,\" but the \"replace\" part has been on backorder since 2010. Maybe it's coming via carrier pigeon? Or perhaps it's just \"don't get sick, snowflake!\"\n",
              "*   **The culture war:** They're constantly fighting the \"culture war,\" bravely standing against things like gender-neutral bathrooms, critical race theory, and apparently, any book written after 1950 that doesn't explicitly mention rugged individualism and apple pie.\n",
              "*   **Their approach to national unity:** \"We just need everyone to agree with us, then we'll have unity! Why is that so hard for you people?\"\n",
              "*   **On government spending:** They hate government spending... unless it's for something with \"defense\" or \"border\" in the title, then it's a blank check.\n",
              "*   **Their favorite news channel:** You can always tell a Republican by their TV; it's permanently glued to a channel where every other word is \"woke,\" \"socialism,\" or \"Hunter Biden's laptop.\"\n",
              "*   **The elephant in the room:** The Republican elephant mascot is slowly evolving into an ostrich, burying its head deeper and deeper in the sand when inconvenient truths come up.\n",
              "\n",
              "It's all in good fun and satire, of course! Humor helps us look at politics from a different angle.\"\"\"\n",
              "      ),\n",
              "    ],\n",
              "    role='model'\n",
              "  ),\n",
              "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "  index=0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}