{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson: The Core of Agency - Function Calling\n",
        "\n",
        "Welcome to this lesson on **Function Calling**, one of the most powerful features of the Gemini API. This is how you give your AI \"hands\" to interact with the world, transforming it from a simple chatbot into a capable agent.\n",
        "\n",
        "### The Concept\n",
        "Function calling allows you to define a set of your own Python functions (we'll call them \"tools\") and make them available to the Gemini model. The model can then intelligently decide when to use these tools based on the user's prompt. It doesn't execute the function itself; instead, it asks *your code* to run the function with the correct arguments.\n",
        "\n",
        "In this notebook, we will:\n",
        "1.  **Build a Smart Home Controller:** A simple agent that can turn lights on or off and play music.\n",
        "2.  **Handle Function Calls:** Learn the complete loop of receiving a function call request, executing your code, and sending the result back to the model.\n",
        "3.  **Implement a Multi-Tool Agent:** Create an agent that has multiple tools and can choose the correct one for the user's request.\n",
        "4. **Compositional Function Calls:** An advanced agent that can chain tools together, using the output of one as the input for another."
      ],
      "metadata": {
        "id": "e-9TDhtom3px"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UuhwkCdJma33"
      },
      "outputs": [],
      "source": [
        "#@title 1. Setup\n",
        "# Install the Google AI Python SDK\n",
        "!pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Configure your API Key\n",
        "# Use the \"Secrets\" tab in Colab (click the key icon on the left) to store your\n",
        "# API key with the name \"GOOGLE_API_KEY\".\n",
        "\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "    print('Secret not found. Please add your GOOGLE_API_KEY to the Colab Secrets Manager.')"
      ],
      "metadata": {
        "id": "QhlRQGium_b9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Building a Smart Home Controller\n",
        "\n",
        "Let's start by defining some simple Python functions that will act as our \"tools\" for controlling a smart home."
      ],
      "metadata": {
        "id": "uSWziEBAvlTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Define the Tools (Python Functions)\n",
        "\n",
        "# This dictionary will simulate the state of our smart home devices\n",
        "smart_home_state = {\n",
        "    \"living_room_light\": False,\n",
        "    \"speaker_playing\": None\n",
        "}\n",
        "\n",
        "def set_light_state(room: str, state: bool):\n",
        "    \"\"\"Turns a light on or off in a specified room.\"\"\"\n",
        "    print(f\"--- TOOL: Turning {room} light {'ON' if state else 'OFF'} ---\")\n",
        "    smart_home_state[f\"{room}_light\"] = state\n",
        "    return {\"status\": \"success\", \"room\": room, \"state\": state}\n",
        "\n",
        "def play_music(artist: str, song: str):\n",
        "    \"\"\"Plays a song by a specified artist.\"\"\"\n",
        "    print(f\"--- TOOL: Playing '{song}' by {artist} ---\")\n",
        "    smart_home_state[\"speaker_playing\"] = f\"{song} by {artist}\"\n",
        "    return {\"status\": \"success\", \"now_playing\": f\"{song} by {artist}\"}\n",
        "\n",
        "smart_home_tools = [set_light_state, play_music]\n",
        "\n",
        "print(\"Smart Home tools defined successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjYP_4Pdvwsp",
        "outputId": "4a1c9861-803e-478b-f154-a13833698edb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smart Home tools defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Make the Tools Available to the Model\n",
        "\n",
        "# Function calls naturally fit into multi-turn conversations. The Python SDK's ChatSession (client.chats.create(...)) is ideal for this, as it automatically handles conversation history.\n",
        "# Furthermore, ChatSession simplifies function calling execution via its automatic_function_calling feature (enabled by default)\n",
        "\n",
        "prompt = \"Can you turn on the light in the living room and then play 'Bohemian Rhapsody' by Queen?\"\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config={\n",
        "        \"tools\": smart_home_tools\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciku591Yv19N",
        "outputId": "17eacd06-ec2a-4951-da4f-1c2a1295aa1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TOOL: Turning living room light ON ---\n",
            "--- TOOL: Playing 'Bohemian Rhapsody' by Queen ---\n",
            "I've turned on the light in the living room and started playing 'Bohemian Rhapsody' by Queen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Examining Function Calls and Execution History\n",
        "# To understand what happened in the background, you can examine the chat history.\n",
        "\n",
        "# The Chat.history property stores a chronological record of the conversation between the user and the Gemini model. You can get the history using Chat.get_history(). Each turn in the conversation is represented by a genai.types.Content object, which contains the following information:\n",
        "\n",
        "# Role: Identifies whether the content originated from the \"user\" or the \"model\".\n",
        "\n",
        "# Parts: A list of genai.types.Part objects that represent individual components of the message. With a text-only model, these parts can be:\n",
        "\n",
        "# Text: Plain text messages.\n",
        "# Function Call (genai.types.FunctionCall): A request from the model to execute a specific function with provided arguments.\n",
        "# Function Response (genai.types.FunctionResponse): The result returned by the user after executing the requested function.\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def print_history(chat):\n",
        "  for content in chat.get_history():\n",
        "      display(Markdown(\"###\" + content.role + \":\"))\n",
        "      for part in content.parts:\n",
        "          if part.text:\n",
        "              display(Markdown(part.text))\n",
        "          if part.function_call:\n",
        "              print(\"Function call: {\", part.function_call, \"}\")\n",
        "          if part.function_response:\n",
        "              print(\"Function response: {\", part.function_response, \"}\")\n",
        "      print(\"-\" * 80)\n",
        "\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "evncnnZyDENU",
        "outputId": "bab12aa3-477a-4812-8f07-823833e13d21"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Can you turn on the light in the living room and then play 'Bohemian Rhapsody' by Queen?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call: { id=None args={'room': 'living room', 'state': True} name='set_light_state' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: { will_continue=None scheduling=None parts=None id=None name='set_light_state' response={'result': {'status': 'success', 'room': 'living room', 'state': True}} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call: { id=None args={'song': 'Bohemian Rhapsody', 'artist': 'Queen'} name='play_music' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: { will_continue=None scheduling=None parts=None id=None name='play_music' response={'result': {'status': 'success', 'now_playing': 'Bohemian Rhapsody by Queen'}} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I've turned on the light in the living room and started playing 'Bohemian Rhapsody' by Queen."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Compositional Reasoning - Chaining Function Calls\n",
        "\n",
        "Now for the most advanced pattern: compositional reasoning. This is when the model needs to chain function calls together, using the output of one function as the input for another to solve a multi-step problem.\n",
        "\n",
        "We'll build an **\"E-commerce Assistant\"** that can first find a product's ID and then use that ID to look up its reviews."
      ],
      "metadata": {
        "id": "WVm8xSDbGQOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Define the Tools for the E-commerce Assistant\n",
        "# Simulate a product database\n",
        "product_db = {\n",
        "    \"Pixel 8 Pro\": { \"product_id\": \"P8PRO-2024\" },\n",
        "    \"Pixel Tablet\": { \"product_id\": \"PTAB-2024\" }\n",
        "}\n",
        "\n",
        "# Simulate a reviews database\n",
        "reviews_db = {\n",
        "    \"P8PRO-2024\": [\"Amazing camera!\", \"The battery life is excellent.\", \"A bit pricey but worth it.\"],\n",
        "    \"PTAB-2024\": [\"Great for media consumption.\", \"The speaker dock is a game-changer.\"]\n",
        "}\n",
        "\n",
        "def search_product(product_name: str):\n",
        "    \"\"\"Finds the product_id for a given product name.\"\"\"\n",
        "    print(f\"--- TOOL: Searching for product: '{product_name}' ---\")\n",
        "    product = product_db.get(product_name)\n",
        "    if product:\n",
        "        return {\"product_id\": product[\"product_id\"]}\n",
        "    else:\n",
        "        return {\"error\": \"Product not found.\"}\n",
        "\n",
        "def get_product_reviews(product_id: str):\n",
        "    \"\"\"Gets the customer reviews for a given product_id.\"\"\"\n",
        "    print(f\"--- TOOL: Fetching reviews for product_id: '{product_id}' ---\")\n",
        "    reviews = reviews_db.get(product_id)\n",
        "    if reviews:\n",
        "        return {\"reviews\": reviews}\n",
        "    else:\n",
        "        return {\"error\": \"Reviews not found for this product_id.\"}\n",
        "\n",
        "product_tools = [search_product, get_product_reviews]\n",
        "\n",
        "print(\"E-commerce tools defined successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RMsknKOGViF",
        "outputId": "2dd1aa84-0277-45f0-b3e8-88326dbaf745"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E-commerce tools defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Make the Tools Available to the Model\n",
        "\n",
        "prompt = \"First find the product ID for the 'Pixel 8 Pro', and then use that ID to tell me what its customer reviews are.\"\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config={\n",
        "        \"tools\": product_tools\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPCRk89tGdof",
        "outputId": "682b1300-dbb7-40bd-dbc2-32a69ab672eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TOOL: Searching for product: 'Pixel 8 Pro' ---\n",
            "--- TOOL: Fetching reviews for product_id: 'P8PRO-2024' ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The customer reviews for the Pixel 8 Pro are: \"Amazing camera!\", \"The battery life is excellent.\", and \"A bit pricey but worth it.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Examining Function Calls and Execution History\n",
        "print_history(chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "H1_NRjMhG3Ft",
        "outputId": "112a5e0a-8e80-4772-c8d5-1c1e7a9b1fd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "First find the product ID for the 'Pixel 8 Pro', and then use that ID to tell me what its customer reviews are."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call: { id=None args={'product_name': 'Pixel 8 Pro'} name='search_product' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: { will_continue=None scheduling=None parts=None id=None name='search_product' response={'result': {'product_id': 'P8PRO-2024'}} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call: { id=None args={'product_id': 'P8PRO-2024'} name='get_product_reviews' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: { will_continue=None scheduling=None parts=None id=None name='get_product_reviews' response={'result': {'reviews': ['Amazing camera!', 'The battery life is excellent.', 'A bit pricey but worth it.']}} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The customer reviews for the Pixel 8 Pro are: \"Amazing camera!\", \"The battery life is excellent.\", and \"A bit pricey but worth it.\""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}